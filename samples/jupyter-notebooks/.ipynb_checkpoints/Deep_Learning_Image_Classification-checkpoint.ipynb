{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Image Classification using Apache SystemML\n",
    "\n",
    "This notebook demonstrates how to train a deep learning model on SystemML for the classic [MNIST](http://yann.lecun.com/exdb/mnist/) problem of mapping images of single digit numbers to their corresponding numeric representations, using a classic [LeNet](http://yann.lecun.com/exdb/lenet/)-like convolutional neural network model. See [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap6.html) for more information on neural networks and deep learning.\n",
    "\n",
    "The downloaded MNIST dataset contains labeled images of handwritten digits, where each example is a 28x28 pixel image of grayscale values in the range [0,255] stretched out as 784 pixels, and each label is one of 10 possible digits in [0,9].  We download 60,000 training examples, and 10,000 test examples, where the images and labels are stored in separate matrices.  We then train a SystemML LeNet-like convolutional neural network (i.e. \"convnet\", \"CNN\") model.  The resulting trained model has an accuracy of 98.6% on the test dataset.\n",
    "\n",
    "1. [Download the MNIST data](#download_data)\n",
    "1. [Train a CNN classifier for MNIST handwritten digits](#train)\n",
    "1. [Detect handwritten Digits](#predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\" markdown=\"1\">\n",
    "![Image of Image to Digit](https://www.wolfram.com/mathematica/new-in-10/enhanced-image-processing/HTMLImages.en/handwritten-digits-classification/smallthumb_10.gif)\n",
    "Mapping images of numbers to numbers\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: This notebook is supported with SystemML 0.14.0 and above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\r\n",
      "Metadata-Version: 1.1\r\n",
      "Name: systemml\r\n",
      "Version: 1.0.0\r\n",
      "Summary: Apache SystemML is a distributed and declarative machine learning platform.\r\n",
      "Home-page: http://systemml.apache.org/\r\n",
      "Author: Apache SystemML\r\n",
      "Author-email: dev@systemml.apache.org\r\n",
      "License: Apache 2.0\r\n",
      "Location: /Users/asurve/.pyenv/versions/3.5.0/lib/python3.5/site-packages\r\n",
      "Requires: numpy, scipy, pandas, Pillow\r\n",
      "\u001b[33mYou are using pip version 7.1.2, however version 9.0.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip show systemml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asurve/.pyenv/versions/3.5.0/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split  # module deprecated in 0.18\n",
    "#from sklearn.model_selection import train_test_split  # use this module for >=0.18\n",
    "from sklearn import metrics\n",
    "from systemml import MLContext, dml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 2.0.2\n",
      "SystemML Version: 1.0.0-SNAPSHOT\n",
      "SystemML Built-Time: 2017-06-27 04:30:02 UTC\n"
     ]
    }
   ],
   "source": [
    "ml = MLContext(sc)\n",
    "print(\"Spark Version: {}\".format(sc.version))\n",
    "print(\"SystemML Version: {}\".format(ml.version()))\n",
    "print(\"SystemML Built-Time: {}\".format(ml.buildTime()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"download_data\"></a>\n",
    "## Download the MNIST data\n",
    "\n",
    "Download the [MNIST data from the MLData repository](http://mldata.org/repository/data/viewslug/mnist-original/), and then split and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST data features: (70000, 784)\n",
      "MNIST data labels: (70000,)\n",
      "Training images, labels: (60000, 784), (60000, 1)\n",
      "Testing images, labels: (10000, 784), (10000, 1)\n",
      "Each image is: 28x28 pixels\n"
     ]
    }
   ],
   "source": [
    "mnist = datasets.fetch_mldata(\"MNIST Original\")\n",
    "\n",
    "print(\"MNIST data features: {}\".format(mnist.data.shape))\n",
    "print(\"MNIST data labels: {}\".format(mnist.target.shape))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    mnist.data, mnist.target.astype(np.uint8).reshape(-1, 1),\n",
    "    test_size = 10000)\n",
    "\n",
    "print(\"Training images, labels: {}, {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Testing images, labels: {}, {}\".format(X_test.shape, y_test.shape))\n",
    "print(\"Each image is: {0:d}x{0:d} pixels\".format(int(np.sqrt(X_train.shape[1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: The following command is not required for code above SystemML 0.14 (master branch dated 05/15/2017 or later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    nn\n",
      "A    nn/README.md\n",
      "A    nn/examples\n",
      "A    nn/examples/Example - MNIST LeNet.ipynb\n",
      "A    nn/examples/Example - MNIST Softmax Classifier.ipynb\n",
      "A    nn/examples/README.md\n",
      "A    nn/examples/caffe2dml\n",
      "A    nn/examples/caffe2dml/models\n",
      "A    nn/examples/caffe2dml/models/imagenet\n",
      "A    nn/examples/caffe2dml/models/imagenet/labels.txt\n",
      "A    nn/examples/caffe2dml/models/imagenet/vgg19\n",
      "A    nn/examples/caffe2dml/models/imagenet/vgg19/VGG_ILSVRC_19_layers_deploy.proto\n",
      "A    nn/examples/caffe2dml/models/imagenet/vgg19/VGG_ILSVRC_19_layers_network.proto\n",
      "A    nn/examples/caffe2dml/models/imagenet/vgg19/VGG_ILSVRC_19_layers_solver.proto\n",
      "A    nn/examples/caffe2dml/models/mnist_lenet\n",
      "A    nn/examples/caffe2dml/models/mnist_lenet/lenet.proto\n",
      "A    nn/examples/caffe2dml/models/mnist_lenet/lenet_solver.proto\n",
      "A    nn/examples/get_mnist_data.sh\n",
      "A    nn/examples/mnist_lenet-predict.dml\n",
      "A    nn/examples/mnist_lenet-train.dml\n",
      "A    nn/examples/mnist_lenet.dml\n",
      "A    nn/examples/mnist_lenet_distrib_sgd-train-dummy-data.dml\n",
      "A    nn/examples/mnist_lenet_distrib_sgd-train.dml\n",
      "A    nn/examples/mnist_lenet_distrib_sgd.dml\n",
      "A    nn/examples/mnist_softmax-predict.dml\n",
      "A    nn/examples/mnist_softmax-train.dml\n",
      "A    nn/examples/mnist_softmax.dml\n",
      "A    nn/layers\n",
      "A    nn/layers/affine.dml\n",
      "A    nn/layers/batch_norm1d.dml\n",
      "A    nn/layers/batch_norm2d.dml\n",
      "A    nn/layers/conv2d.dml\n",
      "A    nn/layers/conv2d_builtin.dml\n",
      "A    nn/layers/conv2d_depthwise.dml\n",
      "A    nn/layers/conv2d_transpose.dml\n",
      "A    nn/layers/conv2d_transpose_depthwise.dml\n",
      "A    nn/layers/cross_entropy_loss.dml\n",
      "A    nn/layers/cross_entropy_loss2d.dml\n",
      "A    nn/layers/dropout.dml\n",
      "A    nn/layers/l1_loss.dml\n",
      "A    nn/layers/l1_reg.dml\n",
      "A    nn/layers/l2_loss.dml\n",
      "A    nn/layers/l2_reg.dml\n",
      "A    nn/layers/log_loss.dml\n",
      "A    nn/layers/lstm.dml\n",
      "A    nn/layers/max_pool2d.dml\n",
      "A    nn/layers/max_pool2d_builtin.dml\n",
      "A    nn/layers/relu.dml\n",
      "A    nn/layers/rnn.dml\n",
      "A    nn/layers/scale_shift1d.dml\n",
      "A    nn/layers/scale_shift2d.dml\n",
      "A    nn/layers/sigmoid.dml\n",
      "A    nn/layers/softmax.dml\n",
      "A    nn/layers/softmax2d.dml\n",
      "A    nn/layers/tanh.dml\n",
      "A    nn/optim\n",
      "A    nn/optim/adagrad.dml\n",
      "A    nn/optim/adam.dml\n",
      "A    nn/optim/rmsprop.dml\n",
      "A    nn/optim/sgd.dml\n",
      "A    nn/optim/sgd_momentum.dml\n",
      "A    nn/optim/sgd_nesterov.dml\n",
      "A    nn/test\n",
      "A    nn/test/README.md\n",
      "A    nn/test/compare_backends\n",
      "A    nn/test/compare_backends/README.md\n",
      "A    nn/test/compare_backends/compare.dml\n",
      "A    nn/test/compare_backends/gen_conv2d.dml\n",
      "A    nn/test/compare_backends/gen_conv2d_bwd_data.dml\n",
      "A    nn/test/compare_backends/gen_conv2d_bwd_filter.dml\n",
      "A    nn/test/compare_backends/gen_maxpool.dml\n",
      "A    nn/test/compare_backends/run_tests.sh\n",
      "A    nn/test/compare_backends/test_conv2d.dml\n",
      "A    nn/test/compare_backends/test_conv2d.sh\n",
      "A    nn/test/compare_backends/test_conv2d_bwd_data.dml\n",
      "A    nn/test/compare_backends/test_conv2d_bwd_data.sh\n",
      "A    nn/test/compare_backends/test_conv2d_bwd_filter.dml\n",
      "A    nn/test/compare_backends/test_conv2d_bwd_filter.sh\n",
      "A    nn/test/compare_backends/test_maxpool.dml\n",
      "A    nn/test/compare_backends/test_maxpool.sh\n",
      "A    nn/test/conv2d_simple.dml\n",
      "A    nn/test/grad_check.dml\n",
      "A    nn/test/max_pool2d_simple.dml\n",
      "A    nn/test/run_tests.dml\n",
      "A    nn/test/test.dml\n",
      "A    nn/test/util.dml\n",
      "A    nn/util.dml\n",
      "Exported revision 5243.\n"
     ]
    }
   ],
   "source": [
    "!svn --force export https://github.com/apache/systemml/trunk/scripts/nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train\"></a>\n",
    "## Train a LeNet-like CNN classifier on the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\" markdown=\"1\">\n",
    "![Image of Image to Digit](http://www.ommegaonline.org/admin/journalassistance/picturegallery/896.jpg)\n",
    "MNIST digit recognition – LeNet architecture\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a LeNet-like CNN model using SystemML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = \"\"\"\n",
    "  source(\"nn/examples/mnist_lenet.dml\") as mnist_lenet\n",
    "\n",
    "  # Scale images to [-1,1], and one-hot encode the labels\n",
    "  images = (images / 255) * 2 - 1\n",
    "  n = nrow(images)\n",
    "  labels = table(seq(1, n), labels+1, n, 10)\n",
    "\n",
    "  # Split into training (55,000 examples) and validation (5,000 examples)\n",
    "  X = images[5001:nrow(images),]\n",
    "  X_val = images[1:5000,]\n",
    "  y = labels[5001:nrow(images),]\n",
    "  y_val = labels[1:5000,]\n",
    "\n",
    "  # Train the model to produce weights & biases.\n",
    "  [W1, b1, W2, b2, W3, b3, W4, b4] = mnist_lenet::train(X, y, X_val, y_val, C, Hin, Win, epochs)\n",
    "\"\"\"\n",
    "out = ('W1', 'b1', 'W2', 'b2', 'W3', 'b3', 'W4', 'b4')\n",
    "prog = (dml(script).input(images=X_train, labels=y_train, epochs=1, C=1, Hin=28, Win=28)\n",
    "                   .output(*out))\n",
    "\n",
    "W1, b1, W2, b2, W3, b3, W4, b4 = ml.execute(prog).get(*out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the trained model to make predictions for the test data, and evaluate the quality of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_predict = \"\"\"\n",
    "  source(\"nn/examples/mnist_lenet.dml\") as mnist_lenet\n",
    "\n",
    "  # Scale images to [-1,1]\n",
    "  X_test = (X_test / 255) * 2 - 1\n",
    "\n",
    "  # Predict\n",
    "  y_prob = mnist_lenet::predict(X_test, C, Hin, Win, W1, b1, W2, b2, W3, b3, W4, b4)\n",
    "  y_pred = rowIndexMax(y_prob) - 1\n",
    "\"\"\"\n",
    "prog = (dml(script_predict).input(X_test=X_test, C=1, Hin=28, Win=28, W1=W1, b1=b1,\n",
    "                                  W2=W2, b2=b2, W3=W3, b3=b3, W4=W4, b4=b4)\n",
    "                           .output(\"y_pred\"))\n",
    "\n",
    "y_pred = ml.execute(prog).get(\"y_pred\").toNumPy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"predict\"></a>\n",
    "## Detect handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that randomly selects a test image, displays the image, and scores it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = int(np.sqrt(X_test.shape[1]))\n",
    "\n",
    "def displayImage(i):\n",
    "  image = (X_test[i]).reshape(img_size, img_size).astype(np.uint8)\n",
    "  imgplot = plt.imshow(image, cmap='gray')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictImage(i):\n",
    "  image = X_test[i].reshape(1, -1)\n",
    "  out = \"y_pred\"\n",
    "  prog = (dml(script_predict).input(X_test=image, C=1, Hin=28, Win=28, W1=W1, b1=b1,\n",
    "                                    W2=W2, b2=b2, W3=W3, b3=b3, W4=W4, b4=b4)\n",
    "                             .output(out))\n",
    "  pred = int(ml.execute(prog).get(out).toNumPy())\n",
    "  return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = np.random.randint(len(X_test))\n",
    "p = predictImage(i)\n",
    "\n",
    "print(\"Image {}\\nPredicted digit: {}\\nActual digit: {}\\nResult: {}\".format(\n",
    "    i, p, int(y_test[i]), p == int(y_test[i])))\n",
    "\n",
    "displayImage(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 28)\n",
    "pd.DataFrame((X_test[i]).reshape(img_size, img_size), dtype='uint')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
