{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 7.1.2, however version 9.0.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip show systemml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!echo 'y' | pip uninstall systemml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/asurve/git/systemml_dl/systemml/target/systemml-1.0.0-SNAPSHOT-python.tgz\n",
      "Requirement already up-to-date: numpy>=1.8.2 in /Users/asurve/.pyenv/versions/3.5.0/lib/python3.5/site-packages (from systemml==1.0.0)\n",
      "Requirement already up-to-date: scipy>=0.15.1 in /Users/asurve/.pyenv/versions/3.5.0/lib/python3.5/site-packages (from systemml==1.0.0)\n",
      "Requirement already up-to-date: pandas in /Users/asurve/.pyenv/versions/3.5.0/lib/python3.5/site-packages (from systemml==1.0.0)\n",
      "Requirement already up-to-date: Pillow>=2.0.0 in /Users/asurve/.pyenv/versions/3.5.0/lib/python3.5/site-packages (from systemml==1.0.0)\n",
      "Requirement already up-to-date: pytz>=2011k in /Users/asurve/.pyenv/versions/3.5.0/lib/python3.5/site-packages (from pandas->systemml==1.0.0)\n",
      "Requirement already up-to-date: python-dateutil>=2 in /Users/asurve/.pyenv/versions/3.5.0/lib/python3.5/site-packages (from pandas->systemml==1.0.0)\n",
      "Requirement already up-to-date: olefile in /Users/asurve/.pyenv/versions/3.5.0/lib/python3.5/site-packages (from Pillow>=2.0.0->systemml==1.0.0)\n",
      "Requirement already up-to-date: six>=1.5 in /Users/asurve/.pyenv/versions/3.5.0/lib/python3.5/site-packages (from python-dateutil>=2->pandas->systemml==1.0.0)\n",
      "Installing collected packages: systemml\n",
      "  Running setup.py install for systemml\n",
      "Successfully installed systemml-1.0.0\n",
      "\u001b[33mYou are using pip version 7.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade /Users/asurve/git/systemml_dl/systemml/target/systemml-1.0.0-SNAPSHOT-python.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SystemML Built-Time:2017-06-27 04:30:02 UTC\n",
      "Archiver-Version: Plexus Archiver\n",
      "Artifact-Id: systemml\n",
      "Build-Jdk: 1.8.0_121\n",
      "Build-Time: 2017-06-27 04:30:02 UTC\n",
      "Built-By: asurve\n",
      "Created-By: Apache Maven 3.3.9\n",
      "Group-Id: org.apache.systemml\n",
      "Main-Class: org.apache.sysml.api.DMLScript\n",
      "Manifest-Version: 1.0\n",
      "Minimum-Recommended-Spark-Version: 2.1.0\n",
      "Version: 1.0.0-SNAPSHOT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from systemml import MLContext\n",
    "ml = MLContext(sc)\n",
    "print (\"SystemML Built-Time:\"+ ml.buildTime())\n",
    "print(ml.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from systemml.mllearn import Caffe2DML\n",
    "from pyspark.sql import SQLContext\n",
    "import numpy as np\n",
    "import urllib, os, scipy.ndimage\n",
    "from PIL import Image\n",
    "import systemml as sml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ImageNet specific parameters\n",
    "img_shape = (3, 224, 224)\n",
    "num_classes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downloads a jpg image, resizes it to 224 and return as numpy array in N X CHW format\n",
    "url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/58/MountainLion.jpg/312px-MountainLion.jpg'\n",
    "outFile = 'test.jpg'\n",
    "# urllib.urlretrieve(url, outFile)\n",
    "input_image = sml.convertImageToNumPyArr(Image.open(outFile), img_shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download the VGG network\n",
    "# urllib.urlretrieve('https://raw.githubusercontent.com/niketanpansare/model_zoo/master/caffe/vision/vgg/ilsvrc12/VGG_ILSVRC_19_layers_solver.proto', 'VGG_ILSVRC_19_layers_solver.proto')\n",
    "# urllib.urlretrieve('https://raw.githubusercontent.com/niketanpansare/model_zoo/master/caffe/vision/vgg/ilsvrc12/VGG_ILSVRC_19_layers_network.proto', 'VGG_ILSVRC_19_layers_network.proto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download deployment file (.prototxt) \n",
    "2. Download caffemodel (.caffemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# urllib.urlretrieve('http://www.robots.ox.ac.uk/~vgg/software/very_deep/caffe/VGG_ILSVRC_19_layers.caffemodel', 'VGG_ILSVRC_19_layers.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home_dir = os.path.expanduser('~')\n",
    "vgg_pretrained_weight_dir = os.path.join(home_dir, 'model_zoo', 'caffe', 'vision', 'vgg', 'ilsvrc12', 'VGG_ILSVRC_19_pretrained_weights')\n",
    "print ('Pretrained dir: ' + vgg_pretrained_weight_dir)\n",
    "# os.makedirs(vgg_pretrained_weight_dir)\n",
    "sml.convert_caffemodel(SparkContext.getOrCreate(), '/Users/asurve/git/systemml_dl/systemml/samples/jupyter-notebooks/VGG_ILSVRC_19_layers_deploy.prototxt', '/Users/asurve/git/systemml_dl/systemml/samples/jupyter-notebooks/VGG_ILSVRC_19_layers.caffemodel', vgg_pretrained_weight_dir, format=\"binary\", is_caffe_installed=False)\n",
    "# sml.convert_caffemodel(sc, 'VGG_ILSVRC_19_layers_network.proto', 'VGG_ILSVRC_19_layers.caffemodel', vgg_pretrained_weight_dir, format=\"binary\", is_caffe_installed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the pretrained model and predict the downloaded image\n",
    "# home_dir = os.path.expanduser('~')\n",
    "# vgg_pretrained_weight_dir = os.path.join(home_dir, 'model_zoo', 'caffe', 'vision', 'vgg', 'ilsvrc12', 'VGG_ILSVRC_19_pretrained_weights')\n",
    "vgg = Caffe2DML(sc, solver='VGG_ILSVRC_19_layers_solver.proto',  input_shape=img_shape)\n",
    "vgg.set(debug=True)\n",
    "vgg.load(vgg_pretrained_weight_dir)\n",
    "vgg.predict(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the pretrained model and predict the downloaded image\n",
    "home_dir = os.path.expanduser('~')\n",
    "alexnet_pretrained_weight_dir = os.path.join(home_dir, 'Documents/Docs/SystemML/models/Caffe', 'weight_dir/bvlc_alexnet')\n",
    "\n",
    "sparkSession = SparkSession.builder \\\n",
    "     .master(\"local\") \\\n",
    "     .appName(\"Alexnet Model Test\") \\\n",
    "     .getOrCreate()\n",
    "\n",
    "alexnet = Caffe2DML(sparkSession, solver='/Users/asurve/Documents/Docs/SystemML/models/Caffe/prototxt/bvlc_alexnet/solver.prototxt', netFilePath='/Users/asurve/Documents/Docs/SystemML/models/Caffe/prototxt/bvlc_alexnet/train_val.prototxt', input_shape=img_shape)\n",
    "alexnet.set(debug=True)\n",
    "alexnet.load(alexnet_pretrained_weight_dir)\n",
    "# alexnet.predict(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['toilet tissue, toilet paper, bathroom tissue'],\n",
       "      dtype='<U44')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet.predict(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('VGG_ILSVRC_19_layers_solver.proto', <http.client.HTTPMessage at 0x107862f98>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Download the VGG network\n",
    "import urllib\n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/niketanpansare/systemml/deconv/scripts/nn/examples/caffe2dml/models/imagenet/vgg19/VGG_ILSVRC_19_layers_deploy.proto', 'VGG_ILSVRC_19_layers_deploy.proto')\n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/niketanpansare/systemml/deconv/scripts/nn/examples/caffe2dml/models/imagenet/vgg19/VGG_ILSVRC_19_layers_network.proto', 'VGG_ILSVRC_19_layers_network.proto')\n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/niketanpansare/systemml/deconv/scripts/nn/examples/caffe2dml/models/imagenet/vgg19/VGG_ILSVRC_19_layers_solver.proto', 'VGG_ILSVRC_19_layers_solver.proto')\n",
    "#urllib.request.urlretrieve('http://www.robots.ox.ac.uk/~vgg/software/very_deep/caffe/VGG_ILSVRC_19_layers.caffemodel', 'VGG_ILSVRC_19_layers.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o54.saveCaffeModelFile.\n: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.sysml.runtime.matrix.data.MatrixBlock.allocateDenseBlock(MatrixBlock.java:362)\n\tat org.apache.sysml.runtime.matrix.data.MatrixBlock.allocateDenseBlock(MatrixBlock.java:336)\n\tat org.apache.sysml.api.dl.Utils$.allocateMatrixBlock(Utils.scala:140)\n\tat org.apache.sysml.api.dl.Utils$$anonfun$readCaffeNet$1.apply(Utils.scala:218)\n\tat org.apache.sysml.api.dl.Utils$$anonfun$readCaffeNet$1.apply(Utils.scala:189)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\n\tat org.apache.sysml.api.dl.Utils$.readCaffeNet(Utils.scala:189)\n\tat org.apache.sysml.api.dl.Utils$.saveCaffeModelFile(Utils.scala:162)\n\tat org.apache.sysml.api.dl.Utils$.saveCaffeModelFile(Utils.scala:157)\n\tat org.apache.sysml.api.dl.Utils.saveCaffeModelFile(Utils.scala:298)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-92e2048e4b4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msystemml\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrained_vgg_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'trained_vgg_weights'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_caffemodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VGG_ILSVRC_19_layers_deploy.proto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VGG_ILSVRC_19_layers.caffemodel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_vgg_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://raw.githubusercontent.com/niketanpansare/systemml/deconv/scripts/nn/examples/caffe2dml/models/imagenet/labels.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_vgg_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asurve/.pyenv/versions/3.5.0/lib/python3.5/site-packages/systemml/converters.py\u001b[0m in \u001b[0;36mconvert_caffemodel\u001b[0;34m(sc, deploy_file, caffemodel_file, output_dir, format, is_caffe_installed)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mcreateJavaObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dummy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mutilObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msysml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUtils\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mutilObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveCaffeModelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaffemodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asurve/Documents/Docs/SystemML/Spark/downloads/spark-2.0.2-bin-hadoop2.7/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asurve/Documents/Docs/SystemML/Spark/downloads/spark-2.0.2-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/asurve/Documents/Docs/SystemML/Spark/downloads/spark-2.0.2-bin-hadoop2.7/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o54.saveCaffeModelFile.\n: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.sysml.runtime.matrix.data.MatrixBlock.allocateDenseBlock(MatrixBlock.java:362)\n\tat org.apache.sysml.runtime.matrix.data.MatrixBlock.allocateDenseBlock(MatrixBlock.java:336)\n\tat org.apache.sysml.api.dl.Utils$.allocateMatrixBlock(Utils.scala:140)\n\tat org.apache.sysml.api.dl.Utils$$anonfun$readCaffeNet$1.apply(Utils.scala:218)\n\tat org.apache.sysml.api.dl.Utils$$anonfun$readCaffeNet$1.apply(Utils.scala:189)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\n\tat org.apache.sysml.api.dl.Utils$.readCaffeNet(Utils.scala:189)\n\tat org.apache.sysml.api.dl.Utils$.saveCaffeModelFile(Utils.scala:162)\n\tat org.apache.sysml.api.dl.Utils$.saveCaffeModelFile(Utils.scala:157)\n\tat org.apache.sysml.api.dl.Utils.saveCaffeModelFile(Utils.scala:298)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Convert the caffemodel to trained_vgg_weights directory\n",
    "import systemml as sml\n",
    "trained_vgg_weights = 'trained_vgg_weights'\n",
    "sml.convert_caffemodel(sc, 'VGG_ILSVRC_19_layers_deploy.proto', 'VGG_ILSVRC_19_layers.caffemodel', trained_vgg_weights)\n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/niketanpansare/systemml/deconv/scripts/nn/examples/caffe2dml/models/imagenet/labels.txt', os.path.join(trained_vgg_weights, 'labels.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
